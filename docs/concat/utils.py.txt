# ==========================================
# GROUPE : utils
# ==========================================


# ------------------------------------------
# FICHIER : utils\json_parser.py
# ------------------------------------------
import json
import logging

logger = logging.getLogger(__name__)

def robust_json_parse(llm_output: str) -> dict | list | None:
    """
    Extrait un JSON (Objet ou Liste) de manière robuste sans Regex complexes.
    """
    if not llm_output:
        return None

    text = llm_output.strip()

    # 1. Nettoyage basique des balises Markdown ```json ... ```
    if "```" in text:
        lines = text.splitlines()
        # On filtre les lignes qui contiennent ```
        text = "\n".join([l for l in lines if "```" not in l]).strip()

    # 2. Recherche des bornes JSON (Optimisé)
    # On cherche le premier '[' ou '{'
    first_square = text.find('[')
    first_curly = text.find('{')
    
    start_index = -1
    is_array = False

    # Détermination du début (lequel arrive en premier ?)
    if first_square != -1 and first_curly != -1:
        if first_square < first_curly:
            start_index = first_square
            is_array = True
        else:
            start_index = first_curly
    elif first_square != -1:
        start_index = first_square
        is_array = True
    elif first_curly != -1:
        start_index = first_curly
    
    if start_index == -1:
        return None

    # Détermination de la fin correspondante
    end_char = ']' if is_array else '}'
    end_index = text.rfind(end_char)

    if end_index == -1 or end_index < start_index:
        return None

    json_candidate = text[start_index : end_index + 1]

    try:
        return json.loads(json_candidate)
    except json.JSONDecodeError as e:
        logger.error(f"JSON Decode Error: {e}")
        return None

# ------------------------------------------
# FICHIER : utils\linkedin_cleaner.py
# ------------------------------------------
# utils/linkedin_cleaner.py
import re
from urllib.parse import urlparse, urlunparse

def clean_linkedin_url(url: str) -> str:
    """
    Nettoie une URL LinkedIn pour ne garder que la partie canonique.
    Ex: https://www.linkedin.com/in/jean-dupont?src=... -> https://www.linkedin.com/in/jean-dupont
    """
    if not url:
        return ""
        
    try:
        # 1. Parsing basique
        parsed = urlparse(url.strip())
        
        # 2. On reconstruit sans les query params (partie après ?) ni fragments (partie après #)
        # On garde scheme (https), netloc (www.linkedin.com) et path (/in/jean-dupont)
        cleaned = urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))
        
        # 3. Retirer le slash final s'il existe (convention souvent utilisée pour les IDs)
        if cleaned.endswith("/"):
            cleaned = cleaned[:-1]
            
        return cleaned
        
    except Exception:
        # Fallback si l'URL est malformée, on renvoie telle quelle
        return url

# ------------------------------------------
# FICHIER : utils\text_extractor.py
# ------------------------------------------
import os
import logging
from pydantic import FilePath
from pypdf import PdfReader

logger = logging.getLogger(__name__)

class TextExtractor:
    @staticmethod
    def extract_from_file(file_path: str) -> str:
        """
        Détecte l'extension et extrait le texte.
        Supporte: .txt, .pdf, .md
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Le fichier n'existe pas : {file_path}")

        _, ext = os.path.splitext(file_path)
        ext = ext.lower()

        try:
            if ext == ".pdf":
                return TextExtractor._read_pdf(file_path)
            elif ext in [".txt", ".md", ".json", ".csv"]:
                return TextExtractor._read_text(file_path)
            else:
                logger.warning(f"⚠️ Extension non supportée pour l'extraction texte : {ext}")
                return ""
        except Exception as e:
            logger.error(f"❌ Erreur lecture fichier {file_path}: {e}")
            raise e

    @staticmethod
    def _read_text(path: str) -> str:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()

    @staticmethod
    def _read_pdf(path: str) -> str:
        text = ""
        reader = PdfReader(path)
        for page in reader.pages:
            content = page.extract_text()
            if content:
                text += content + "\n"
        return text

text_extractor = TextExtractor()
