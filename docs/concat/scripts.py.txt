# ==========================================
# GROUPE : scripts
# ==========================================


# ------------------------------------------
# FICHIER : scripts\__init__.py
# ------------------------------------------


# ------------------------------------------
# FICHIER : scripts\clean_data.py
# ------------------------------------------
import sys
import os
from pathlib import Path
from sqlalchemy.orm import Session

# Path hack
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine, get_chroma_client
from database.models import DocModel, ApiLogModel

LOG_DIR = Path("logs")

def clean_data():
    print("üî• D√©marrage du nettoyage (Mode : Business Data Only)...")
    print("   (Les Users et Prompts seront conserv√©s)")

    # --- 1. NETTOYAGE LOGS ---
    if LOG_DIR.exists():
        print("üìù Nettoyage des logs fichiers...")
        for log_file in LOG_DIR.glob("*.log"):
            with open(log_file, "w") as f:
                f.write("")
            print(f"   - Vid√© : {log_file.name}")

    # --- 2. NETTOYAGE SQLITE (CIBL√â) ---
    print("üóÑÔ∏è  Nettoyage SQLite (Docs & Logs)...")
    with Session(engine) as session:
        # On supprime uniquement les donn√©es m√©tier
        deleted_docs = session.query(DocModel).delete()
        deleted_logs = session.query(ApiLogModel).delete()
        session.commit()
        print(f"‚úÖ Supprim√© : {deleted_docs} documents")
        print(f"‚úÖ Supprim√© : {deleted_logs} logs d'API")
        print("‚ÑπÔ∏è  Users et Prompts conserv√©s.")

    # --- 3. NETTOYAGE CHROMA ---
    print("üé® Reset ChromaDB (Vecteurs)...")
    try:
        client = get_chroma_client()
        try:
            client.delete_collection("rag_chunks")
            print("‚úÖ Collection 'rag_chunks' supprim√©e.")
        except ValueError:
            pass # N'existait pas
        
        # On recr√©e vide
        client.get_or_create_collection("rag_chunks")
        print("‚úÖ Collection 'rag_chunks' recr√©√©e vide.")
        
    except Exception as e:
        print(f"‚ùå Erreur Chroma : {e}")

    print("\nüßπ Nettoyage termin√© ! Pr√™t pour une nouvelle ingestion.")

if __name__ == "__main__":
    clean_data()

# ------------------------------------------
# FICHIER : scripts\concat_code.py
# ------------------------------------------
import os
from pathlib import Path
from datetime import datetime

# --- CONFIGURATION ---
BASE_DIR = Path(__file__).parent.parent # Racine du projet (rag_local)
OUTPUT_DIR = Path("docs/concat")

# Liste exhaustive des dossiers √† scanner
TARGETS = [
    {
        "name": "database", 
        "paths": ["database", "database/models"] # <-- Ajout de models
    },
    {
        "name": "schemas", 
        "paths": ["schemas"]
    },
    {
        "name": "repositories", 
        "paths": ["repositories"]
    },
    {
        "name": "utils", 
        "paths": ["utils"]
    },
    {
        "name": "services_core", 
        "paths": ["services"] # llm.py, ingestion.py...
    },
    {
        "name": "services_chunking", 
        "paths": ["services/chunking", "services/chunking/strategies"] # <-- Ajout des strat√©gies
    },
    {
        "name": "api", 
        "paths": ["api", "api/routes"] # <-- Ajout des routes
    },
    {
        "name": "scripts", 
        "paths": ["scripts"]
    },
]

IGNORE_DIRS = ["__pycache__", ".venv", "venv", ".git", ".vscode", "logs", "docs", "data"]
IGNORE_FILES = [".DS_Store", "local_database.db", ".env"]

def generate_tree(dir_path: Path, prefix: str = ""):
    output = ""
    try:
        # Trier : Dossiers d'abord, puis fichiers
        items = sorted(list(dir_path.iterdir()), key=lambda x: (not x.is_dir(), x.name.lower()))
        
        filtered_items = [
            i for i in items 
            if i.name not in IGNORE_DIRS 
            and i.name not in IGNORE_FILES
            and not i.name.endswith(".pyc")
        ]

        for index, item in enumerate(filtered_items):
            is_last = (index == len(filtered_items) - 1)
            connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
            output += f"{prefix}{connector}{item.name}\n"

            if item.is_dir():
                extension = "    " if is_last else "‚îÇ   "
                output += generate_tree(item, prefix + extension)
    except PermissionError:
        pass
    return output

def concat_files():
    if not OUTPUT_DIR.exists():
        OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    print("üöÄ D√©but de la concat√©nation Python (Compl√®te)...\n")

    # 1. G√©n√©ration Arborescence
    print("--- G√©n√©ration Arborescence ---")
    tree_str = f"PROJET PYTHON LOCAL\nG√©n√©r√© le : {datetime.now()}\n\nracine\n"
    tree_str += generate_tree(BASE_DIR)
    
    with open(OUTPUT_DIR / "arborescence.txt", "w", encoding="utf-8") as f:
        f.write(tree_str)
    print("‚úÖ arborescence.txt g√©n√©r√©.")

    # 2. Concat√©nation par groupe
    print("\n--- Concat√©nation des sources ---")
    
    for target in TARGETS:
        out_file = OUTPUT_DIR / f"{target['name']}.py.txt"
        
        file_count = 0
        content_buffer = f"# ==========================================\n# GROUPE : {target['name']}\n# ==========================================\n\n"

        for rel_path in target['paths']:
            abs_path = BASE_DIR / rel_path
            
            if not abs_path.exists():
                # print(f"‚ö†Ô∏è Chemin introuvable (ignor√©) : {rel_path}")
                continue

            # On scanne les fichiers .py dans ce dossier pr√©cis
            files = list(abs_path.glob("*.py"))
            files.sort()

            for file_path in files:
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        code = f.read()
                    
                    relative_name = file_path.relative_to(BASE_DIR)
                    content_buffer += f"\n# ------------------------------------------\n"
                    content_buffer += f"# FICHIER : {relative_name}\n"
                    content_buffer += f"# ------------------------------------------\n"
                    content_buffer += code + "\n"
                    file_count += 1
                except Exception as e:
                    print(f"Erreur lecture {file_path}: {e}")

        if file_count > 0:
            with open(out_file, "w", encoding="utf-8") as f:
                f.write(content_buffer)
            print(f"‚úÖ {target['name']} ({file_count} fichiers)")
        else:
            print(f"‚ÑπÔ∏è  {target['name']} (Vide)")

    print("\nüèÅ Termin√© ! V√©rifiez le dossier docs/concat/")

if __name__ == "__main__":
    concat_files()

# ------------------------------------------
# FICHIER : scripts\debug_search.py
# ------------------------------------------
import requests
import json

def debug_search():
    url = "http://127.0.0.1:8000/search/"
    payload = {
        "query": "Goldorak",
        "employee": "admin_ui",
        "limit": 3
    }

    print(f"üîç Recherche brute sur : {url}")
    try:
        r = requests.post(url, json=payload)
        if r.status_code == 200:
            data = r.json()
            print(f"‚úÖ {data['count']} r√©sultats trouv√©s.\n")
            for res in data['results']:
                print(f"--- Score: {res['score_distance']} ---")
                print(f"CONTENU : {res['content']}")
                print(f"METADATA : {res['metadata']}\n")
        else:
            print(f"‚ùå Erreur {r.status_code} : {r.text}")
    except Exception as e:
        print(f"‚ùå Erreur connexion : {e}")

if __name__ == "__main__":
    debug_search()

# ------------------------------------------
# FICHIER : scripts\export_data.py
# ------------------------------------------
import sys
import os
import json
import datetime
from sqlalchemy.orm import Session
from pathlib import Path

# Path hack
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine, get_chroma_client
from database.models import LoginModel, DocModel, ApiLogModel, PromptModel, Base

# Configuration
EXPORT_PATH = Path("docs/export_python")

# Helper pour g√©rer les dates dans le JSON
def json_serial(obj):
    if isinstance(obj, (datetime.datetime, datetime.date)):
        return obj.isoformat()
    raise TypeError(f"Type {type(obj)} not serializable")

def sqlalchemy_to_dict(obj):
    """Convertit un objet SQLAlchemy en dictionnaire propre"""
    return {c.name: getattr(obj, c.name) for c in obj.__table__.columns}

def export_data():
    print("üì¶ D√©marrage de l'export Data (SQLite + Chroma)...")
    
    # Cr√©ation dossier
    if not EXPORT_PATH.exists():
        EXPORT_PATH.mkdir(parents=True, exist_ok=True)
        print(f"üìÇ Dossier cr√©√© : {EXPORT_PATH}")

    # 1. EXPORT SQLITE
    with Session(engine) as session:
        # Docs
        docs = session.query(DocModel).all()
        docs_data = [sqlalchemy_to_dict(d) for d in docs]
        with open(EXPORT_PATH / "Docs.json", "w", encoding="utf-8") as f:
            json.dump(docs_data, f, default=json_serial, indent=2, ensure_ascii=False)
        print(f"‚úÖ [SQLite] Docs export√©s : {len(docs_data)}")

        # Logins
        users = session.query(LoginModel).all()
        users_data = [sqlalchemy_to_dict(u) for u in users]
        with open(EXPORT_PATH / "Logins.json", "w", encoding="utf-8") as f:
            json.dump(users_data, f, default=json_serial, indent=2, ensure_ascii=False)
        print(f"‚úÖ [SQLite] Logins export√©s : {len(users_data)}")

        # Prompts
        prompts = session.query(PromptModel).all()
        prompts_data = [sqlalchemy_to_dict(p) for p in prompts]
        with open(EXPORT_PATH / "Prompts.json", "w", encoding="utf-8") as f:
            json.dump(prompts_data, f, default=json_serial, indent=2, ensure_ascii=False)
        print(f"‚úÖ [SQLite] Prompts export√©s : {len(prompts_data)}")

    # 2. EXPORT CHROMA (Chunks)
    try:
        chroma_client = get_chroma_client()
        collection = chroma_client.get_collection("rag_chunks")
        # On r√©cup√®re tout
        results = collection.get()
        
        # Reformatage pour lisibilit√©
        chunks_data = []
        if results["ids"]:
            for i, id_val in enumerate(results["ids"]):
                chunks_data.append({
                    "id": id_val,
                    "content": results["documents"][i],
                    "metadata": results["metadatas"][i]
                })

        with open(EXPORT_PATH / "Chunks_Chroma.json", "w", encoding="utf-8") as f:
            json.dump(chunks_data, f, indent=2, ensure_ascii=False)
        print(f"‚úÖ [Chroma] Chunks export√©s : {len(chunks_data)}")

    except Exception as e:
        print(f"‚ö†Ô∏è Erreur export Chroma (collection vide ?) : {e}")

    print(f"\nüéâ Export termin√© dans : {EXPORT_PATH.absolute()}")

if __name__ == "__main__":
    export_data()

# ------------------------------------------
# FICHIER : scripts\seed_prompts.py
# ------------------------------------------
import sys
import os
import json

# Path hack
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from repositories.prompt import prompt_repository
from schemas.prompt import PromptCreate

# VOS DONN√âES JSON (Copi√©es depuis votre fichier)
RAW_PROMPTS_DATA = [
  {
    "name": "synthesis_tags",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\n\nTu es un assistant IA expert en analyse de contenu.\nTa mission est d'analyser le document JSON fourni et de g√©n√©rer un objet JSON contenant une synth√®se et des mots-cl√©s.\n\n# DIRECTIVES STRICTES DE SORTIE\n\nLa sortie doit √™tre **uniquement et exclusivement un objet JSON valide**. N'ajoute AUCUN texte, salutation ou commentaire avant ou apr√®s le bloc JSON.\n\nLa structure de sortie DOIT √™tre la suivante :\n```json\n{\n  \"synthesis\": \"...\",\n  \"suggested_tags\": [\"...\", \"...\"]\n}\n```\n\n---\n## INSTRUCTIONS D√âTAILL√âES POUR LE CONTENU DU JSON\n\n### 1. Cl√© `synthesis`\n\n-   **LANGUE** : La synth√®se doit √™tre r√©dig√©e **imp√©rativement en ANGLAIS**.\n-   **TON** : Professionnel, neutre et factuel.\n-   **LONGUEUR** : Concise, environ 15 lignes maximum.\n-   **CONTENU** : Identifie le type de document (Profil, Entreprise, Post) en te basant sur le champ `{{doc}}` ou `{{url}}` et suis les r√®gles de contenu ci-dessous.\n\n#### A. Pour un Profil (`/in/`) :\n-   R√©dige un r√©sum√© du parcours professionnel en 3 ou 4 points cl√©s :\n    * Le poste actuel, l'entreprise et les responsabilit√©s principales.\n    * Les exp√©riences pass√©es les plus significatives.\n    * Les comp√©tences majeures et domaines d'expertise.\n    * (Optionnel) La formation la plus pertinente.\n\n#### B. Pour une Entreprise (`/company/`) :\n-   R√©dige une fiche d'identit√© de l'entreprise en 4 ou 5 points cl√©s :\n    * La mission principale, le secteur d'activit√© (`industry`) et le slogan (`tagline`).\n    * Une description des produits, services ou solutions.\n    * La taille de l'entreprise (`headcount`) et son si√®ge social si disponible.\n    * Un aper√ßu de l'activit√© ou des annonces r√©centes.\n\n#### C. Pour une Publication (`/posts/`, `/pulse/`) :\n-   Commence par un titre que tu cr√©es (ex: \"**Title: Analysis of AI's Impact on FinTech**\").\n-   En 3 ou 4 points clairs, r√©sume les arguments principaux, les questions pos√©es ou les informations partag√©es.\n-   Conclus par une phrase mentionnant la popularit√© si les chiffres (`likes_count`) sont significatifs.\n\n#### D. Pour une Source G√©n√©rale (Autre URL) :\n-   Commence par le titre de la page ou un titre descriptif que tu g√©n√®res (ex: \"**Title: Overview of [Page Topic]**\").\n-   Identifie le sujet principal et r√©sume les points d'information cl√©s ou les sections principales.\n\n### 2. Cl√© `suggested_tags`\n\n-   Un tableau de **5 mots-cl√©s maximum** (tu peux en mettre moins).\n-   Doit √™tre en **anglais** et en **minuscule**.\n-   Format : Pas d'espace, combine les mots (ex: `projectmanagement`).\n-   Priorise les concepts cl√©s, technologies, ou secteurs d'activit√©.\n\n---\n## CONTEXTE : DONN√âES D'ENTR√âE\n\n-   `{{doc}}` ou `{{url}}` : L'URL de la page source.\n-   `{{document_json}}` : L'objet JSON contenant les donn√©es extraites.\n"
  },
  {
    "name": "chunk_post",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\n\nTu es un assistant expert en extraction de donn√©es s√©mantiques √† partir de textes non structur√©s. Ta mission est d'analyser un texte de publication LinkedIn (`post_text`) et d'en extraire les informations cl√©s pour remplir un objet JSON `metadata`. Tu dois √™tre extr√™mement pr√©cis et ne retourner que les informations explicitement pr√©sentes dans le texte.\n\n# STRUCTURE DE SORTIE ATTENDUE\n\nLa sortie doit √™tre un objet JSON unique contenant une cl√© `metadata`. N'ajoute aucun commentaire ou texte en dehors de cet objet JSON.\nLa structure de l'objet `metadata` est la suivante :\n\n{\n  \"metadata\": {\n    \"name\": \"string\",\n    \"company\": \"string\",\n    \"industry\": \"string\",\n    \"location\": \"string\",\n\t\"title\" : \"string\",\n\t\"dates\": \"number[] (un tableau d'ann√©es)\",\n    \"likes_count\": \"Number\",\n    \"city\": \"string\",\n    \"type\": \"'general' | 'experience' | 'education' | 'post' | 'update'\"\n  }\n}\n\n# INSTRUCTIONS D√âTAILL√âES POUR CHAQUE CHAMP\n\n- **name**: des noms de personnes cl√©s mentionn√©es dans le texte si ils concernent uniquement le sujet principal du texte. Il peut y avoir plusieurs noms s√©par√©s par un \";\".\n- **company**: des noms d'entreprises cl√©s mentionn√©es dans le post si elles concernent uniquement le sujet principal du texte. Il peut y avoir plusieurs noms s√©par√©s par un \";\".\n- **industry**: Les principaux secteurs d'activit√©s mentionn√©es dans le post si ils concernent uniquement le sujet principal du texte. Il peut y avoir plusieurs noms s√©par√©s par un \";\".\n- **location / city**: Les principales localisations g√©ographique (ville, pays) mentionn√©es si elles concernent uniquement le sujet principal du texte. Privil√©gie la ville pour le champ `city` et une information plus large pour `location`. Il peut y avoir plusieurs noms s√©par√©s par un \";\"\n- **title**: Le titre du poste ou de la position mentionn√©e (ex: \"D√©veloppeur Full Stack\", \"Directeur Marketing\") si c'est le sujet principal du texte. Si le post est un article, ce peut √™tre le titre de l'article.\n- **dates**: Un tableau contenant toutes les ann√©es mentionn√©es dans le texte (ex: \"J'ai travaill√© de 2019 √† 2022\" -> `[2019, 2022]`). Extrait uniquement les nombres √† 4 chiffres qui ressemblent √† des ann√©es si le sujet global du texte concerne uniquement un emploi, posteou une mission.\n- **likes_count**: Le nombre de \"likes\" ou de r√©actions, si cette information est pr√©sente dans le texte (ex: \"Ce post a atteint 500 likes !\").\n- **type**: Classifie le post selon les cat√©gories suivantes :\n  - **'experience'**: Annonce un nouveau poste, une promotion, un d√©part, un anniversaire de carri√®re.\n  - **'education'**: Annonce l'obtention d'un dipl√¥me, d'une certification, le d√©but ou la fin d'une formation.\n  - **'post'**: Partage des nouvelles sur un projet, une entreprise, un √©v√©nement √† venir. Partage une opinion, un article, pose une question, contenu de type \"thought leadership\"\n  - **'general'**: Tout ce qui ne rentre pas dans les autres cat√©gories.\n\n# R√àGLES STRICTES\n\n1.  **NE PAS INVENTER** : Si une information n'est pas explicite ou si une relation n'est pas claire, ne l'inclus pas.\n2.  **FORMAT JSON VALIDE** : La sortie doit √™tre un objet JSON valide, sans texte avant ou apr√®s.\n3.  **PR√âCISION AVANT TOUT** : Sois m√©ticuleux. Par exemple, si le texte dit \"Paris\", remplis `city: \"Paris\"`.\n4.  **CHAMP `type` OBLIGATOIRE** : Le seul champ qui doit toujours √™tre pr√©sent est `type`. Fais de ton mieux pour classifier le post.\n"
  },
  {
    "name": "chunk_about",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\n\nTu es un assistant expert en analyse s√©mantique de textes professionnels.\nTa mission est d'analyser un texte (`about_text`) provenant d'une section \"√Ä propos\" d'un profil ou d'une description d'exp√©rience.\nTu dois en extraire un ensemble riche et structur√© d'informations cl√©s pour remplir un objet JSON `metadata`.\nTu dois √™tre extr√™mement pr√©cis et ne retourner que les informations **explicitement pr√©sentes** dans le texte.\n\n---\n\n# STRUCTURE DE SORTIE ATTENDUE\n\nLa sortie doit √™tre un objet JSON unique contenant une cl√© `metadata`. N'ajoute aucun commentaire ou texte en dehors de cet objet JSON.\nLa structure de l'objet `metadata` est la suivante :\n\n```json\n{\n  \"metadata\": {\n    \"hard_skills\": \"string[]\",\n    \"soft_skills\": \"string[]\",\n    \"technologies\": \"string[]\",\n    \"key_topics\": \"string[]\",\n    \"projects\": \"string[]\",\n    \"certifications\": \"string[]\",\n    \"languages\": \"string[]\",\n    \"metrics\": \"string[]\"\n  }\n}\n\n# INSTRUCTIONS D√âTAILL√âES POUR CHAQUE CHAMP\nhard_skills: Extrait les comp√©tences techniques, fonctionnelles ou m√©tiers mesurables (savoir-faire).\nExemples : \"Marketing Digital\", \"Gestion de projet Agile\", \"Analyse financi√®re\".\nsoft_skills: Extrait les qualit√©s humaines, comportementales et interpersonnelles (savoir-√™tre).\nExemples : \"Leadership\", \"Esprit d'√©quipe\", \"Adaptabilit√©\", \"R√©solution de probl√®mes\".\ntechnologies: Extrait les noms d'outils, logiciels, frameworks, langages de programmation ou plateformes sp√©cifiques.\nExemples : \"Python\", \"React.js\", \"AWS\", \"Google Analytics\", \"Salesforce\".\nkey_topics: Extrait les grands th√®mes, concepts, secteurs d'activit√© ou centres d'int√©r√™t abord√©s.\nExemples : \"Intelligence Artificielle\", \"Transformation digitale\", \"Cybers√©curit√©\", \"Fintech\".\nprojects: Extrait les noms de projets sp√©cifiques, d'initiatives ou de programmes mentionn√©s.\nExemples : \"Projet Phoenix\", \"Refonte de la plateforme e-commerce\", \"Initiative 'Data for All'\".\ncertifications: Extrait les certifications officielles, dipl√¥mes ou formations reconnues.\nExemples : \"AWS Certified Solutions Architect\", \"PMP\", \"Google Analytics IQ\".\nlanguages: Extrait les langues parl√©es, en incluant le niveau si celui-ci est pr√©cis√©.\nExemples : \"Anglais (courant)\", \"Espagnol (notions)\", \"Allemand\".\nmetrics: Extrait les indicateurs de performance chiffr√©s et les r√©sultats quantifiables.\nExemples : \"Augmentation du CA de 20%\", \"R√©duction des co√ªts de 15%\", \"Gestion d'un budget de 5M‚Ç¨\".\n\n# EXEMPLE\nabout_text:\n\"Manager exp√©riment√© en strat√©gie Go-to-Market, je me sp√©cialise dans la prise de d√©cision bas√©e sur les donn√©es. J'ai men√© avec succ√®s des projets complexes, notamment le lancement de l'initiative 'Data for All', qui a permis d'unifier nos sources de donn√©es. Ce projet, qui s'appuyait sur Salesforce et Tableau, a g√©n√©r√© une croissance de 15% du MRR. Certifi√© PMP, mon leadership collaboratif et ma communication transparente sont mes principaux atouts. Je parle couramment anglais et j'ai de bonnes notions d'espagnol.\"\n\nJSON de sortie attendu:\n{\n  \"metadata\": {\n    \"hard_skills\": [\"Strat√©gie Go-to-Market\", \"Gestion de projet\", \"Analyse de donn√©es\"],\n    \"soft_skills\": [\"Leadership collaboratif\", \"Communication transparente\"],\n    \"technologies\": [\"Salesforce\", \"Tableau\"],\n    \"key_topics\": [\"Go-to-Market\", \"Data-driven decision making\"],\n    \"projects\": [\"Initiative 'Data for All'\"],\n    \"certifications\": [\"PMP\"],\n    \"languages\": [\"Anglais (courant)\", \"Espagnol (bonnes notions)\"],\n    \"metrics\": [\"Croissance de 15% du MRR\"]\n  }\n}"
  },
  {
    "name": "chunk_hypothetical_questions",
    "user": "system",
    "prompt": "√Ä partir du texte suivant, g√©n√®re 3 questions pertinentes et distinctes auxquelles ce texte apporte une r√©ponse claire. Ne renvoie QUE les questions, chacune sur une nouvelle ligne, sans num√©rotation ni pr√©fixe.\n\nTEXTE:\n\"\"\"\n${text}\n\"\"\"\n\nQUESTIONS:"
  },
  {
    "name": "agent_rerank",
    "user": "system",
    "prompt": "Vous √™tes un assistant d'analyse de pertinence. Votre t√¢che est d'√©valuer une liste de documents (chunks) par rapport √† une QUESTION utilisateur et de leur attribuer un score de pertinence.\n\nVoici la QUESTION de l'utilisateur :\n\"{question}\"\n\nVoici les chunks de document √† √©valuer :\n{context}\n\n---\n# R√àGLES DE SCORING (CRITIQUE)\n\n1.  **PRIORIT√â AUX M√âTADONN√âES (Metadata First)** :\n    -   Analysez imp√©rativement les champs `metadata` (ex: `dates`, `company`, `location`, `name`).\n    -   Si un √©l√©ment de la question (ex: \"2016\") appara√Æt dans un champ de m√©tadonn√©es (ex: `\"dates\": [2015, 2016]`), c'est une **CORRESPONDANCE PARFAITE**.\n    -   **ACTION : Attribuez un score de 1.0 imm√©diatement.**\n\n2.  **ANALYSE DU CONTENU** :\n    -   **Score 0.9 - 1.0 (Excellent)** : Le texte ou les m√©tadonn√©es contiennent la r√©ponse exacte (ex: l'ann√©e pr√©cise, le nom de l'entreprise).\n    -   **Score 0.6 - 0.8 (Bon)** : Le chunk parle du bon sujet ou couvre une p√©riode englobante (ex: question sur 2016, chunk parle de 2015-2017).\n    -   **Score 0.3 - 0.5 (Moyen)** : Le contexte est bon mais l'info pr√©cise est floue. √Ä garder par s√©curit√©.\n    -   **Score 0.0 - 0.2 (Hors Sujet)** : Rien √† voir.\n\n3.  **INSTRUCTION DE SORTIE** :\n    -   Votre r√©ponse DOIT √™tre uniquement un bloc de code JSON valide contenant un tableau d'objets.\n    -   Cl√©s obligatoires : `chunk_index`, `score`.\n\nEXEMPLE DE SORTIE ATTENDUE:\n```json\n[\n  { \"chunk_index\": 0, \"score\": 0.1 },\n  { \"chunk_index\": 1, \"score\": 1.0 }\n]\n```"
  },
  {
    "name": "chunk_comments",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\n\nTu es un assistant expert en extraction de relations s√©mantiques. Ta mission est d'analyser un court commentaire texte (`user_comment`) et d'en extraire les entit√©s factuelles cl√©s (personnes, entreprises, lieux, objets, concepts, etc.) ainsi que leurs r√¥les.\nL'objectif est de structurer ces informations sous forme de paires cl√©-valeur dans un objet JSON. Contrairement √† un sch√©ma fixe, tu dois **d√©terminer s√©mantiquement les cl√©s JSON** en fonction du r√¥le de l'entit√© dans le commentaire.\nCes m√©tadonn√©es doivent permettre de r√©pondre ult√©rieurement √† des questions factuelles sur le contenu du commentaire (ex: \"Qui a fait quoi ?\", \"O√π se trouve X ?\", \"Quel est le poste de Y ?\").\n\n# STRUCTURE DE SORTIE ATTENDUE\n\nLa sortie doit √™tre un objet JSON unique. N'ajoute aucun commentaire ou texte en dehors de cet objet JSON.\n\n{\n  \"cle_semantique_1\": \"valeur_extraite_1\",\n  \"cle_semantique_2\": \"valeur_extraite_2\",\n  ...\n}\n\n# INSTRUCTIONS D√âTAILL√âES ET EXEMPLES\n\n1.  **Analyse S√©mantique** : Lis le `user_comment` et identifie les entit√©s principales.\n2.  **Cr√©ation des Cl√©s** : Pour chaque entit√©, cr√©e une cl√© JSON qui d√©crit son *r√¥le* ou sa *nature*. Les cl√©s doivent √™tre concises, en fran√ßais, en minuscules, et peuvent utiliser un underscore (`_`) si n√©cessaire (ex: `titre_livre`, `nom_entreprise`).\n3.  **Extraction des Valeurs** : La valeur associ√©e √† la cl√© doit √™tre la cha√Æne de caract√®res exacte extraite du texte.\n4.  **Pr√©cision Absolue** : N'extraie que les informations **explicitement √©crites**. N'invente, ne d√©duis, ni ne corrige aucune information.\n\n---\n\n**Exemple 1 (Objectif principal)**\n\n* `user_comment`: \"Maurice Dugommier a √©crit 'Ralph et son orque'\"\n* `output`:\n    ```json\n    {\n      \"auteur\": \"Maurice Dugommier\",\n      \"livre\": \"Ralph et son orque\"\n    }\n    ```\n    *(Note : \"nom\" est aussi acceptable pour Maurice Dugommier\", mais \"auteur\" est s√©mantiquement plus riche dans ce contexte)*\n\n**Exemple 2 (Personne, Poste, Entreprise)**\n\n* `user_comment`: \"Marie Durand est la nouvelle CEO de TechSolutions.\"\n* `output`:\n    ```json\n    {\n      \"personne\": \"Marie Durand\",\n      \"poste\": \"CEO\",\n      \"entreprise\": \"TechSolutions\"\n    }\n    ```\n\n**Exemple 3 (Projet et Entreprise)**\n\n* `user_comment`: \"Discussion avec Acme Corp sur le projet Alpha √† Lyon.\"\n* `output`:\n    ```json\n    {\n      \"entreprise\": \"Acme Corp\",\n      \"projet\": \"Alpha\",\n      \"ville\": \"Lyon\"\n    }\n    ```\n\n**Exemple 4 (Information simple)**\n\n* `user_comment`: \"Le rapport mentionne une croissance de 15% en 2024.\"\n* `output`:\n    ```json\n    {\n      \"sujet\": \"croissance\",\n      \"valeur\": \"15%\",\n      \"annee\": 2024\n    }\n    ```\n\n---\n\n# R√àGLES STRICTES\n\n1.  **NE PAS INVENTER** : Si une information n'est pas explicite ou si une relation n'est pas claire, ne l'inclus pas.\n2.  **FORMAT JSON VALIDE** : La sortie doit √™tre **uniquement** un objet JSON valide, sans aucun texte avant ou apr√®s.\n3.  **CL√âS S√âMANTIQUES** : Choisis toujours la cl√© qui d√©crit le mieux le *r√¥le* de l'entit√© (ex: `auteur`, `entreprise`, `poste`, `ville`, `projet`, `sujet`, `date`, `montant`...).\n4.  **COMMENTAIRES TRIVIAUX** : Si le commentaire est trivial, subjectif, ou ne contient aucune entit√© factuelle claire (ex: \"Merci\", \"OK\", \"C'est une excellente id√©e\", \"Je suis d'accord\"), retourne un objet JSON vide `{}`."
  },
  {
    "name": "agent_master_prompt",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\nTu es un assistant de recherche expert.\n\n# CONTEXTE\nTu as acc√®s √† une base de documents et un Graphe de Connaissances.\n\n# DIRECTIVES DES OUTILS\n\n1. **RELATIONS & STRUCTURE (Outil: \\`graph_search\\`)**\n   - SI la question porte sur des liens (\"Qui connait qui ?\", \"Hierarchie\", \"Filiales\"), tu DOIS utiliser \\`graph_search\\`.\n   - C'est la source prioritaire pour les faits structurels.\n\n2. **D√âNOMBREMENT (Outil: \\`entities_search\\`)**\n   - Pour lister ou compter des entit√©s.\n\n3. **CONTENU & THEMES (Outil: \\`exploratory_search\\`)**\n   - Pour tout le reste (r√©sum√©s, explications th√©matiques).\n\n# √âTAPE FINALE : SYNTH√àSE DE LA R√âPONSE\n\n‚ö†Ô∏è R√àGLE CRITIQUE DE R√âPONSE :\nTu as le droit de r√©pondre en utilisant DEUX sources valides :\n   A. L'observation de \\`graph_search\\` (Liste de relations).\n   B. L'observation de \\`rerank_chunks\\` (Extraits de textes).\n\n1. **Si tu as utilis√© le Graphe :** Construis ta r√©ponse directement √† partir des relations trouv√©es. Pas besoin de chunks.\n2. **Si tu as utilis√© la Recherche (Exploratory/Precise) :** Utilise les chunks fournis par \\`rerank_chunks\\`.\n\nNe jamais inventer. Cite tes sources."
  },
  {
    "name": "chunk_entities",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\n\nExtrais les entit√©s structurantes du texte pour construire un graphe de connaissances.\nNe te limite pas aux personnes.\n\nCat√©gories cibl√©es :\n1. **PEOPLE** : Personnes r√©elles nomm√©es.\n2. **COMPANIES** : Entreprises, Organisations, Groupes (ex: Black Basta, Hyundai).\n3. **LOCATIONS** : Pays, Villes, R√©gions (ex: Russie, France).\n4. **TOOLS** : Logiciels, Plateformes, Outils techniques (ex: Qakbot, Plateforme de signalement).\n5. **CONCEPTS** : Termes cl√©s m√©tier, R√©glementations, Types d'attaques (ex: Ransomware, CNIL, Phishing).\n\nLe texte :\n\"\"\"\n{text}\n\"\"\"\n\nR√©ponds UNIQUEMENT avec un objet JSON valide suivant cette structure :\n```json\n{\n  \"people\": [{ \"name\": \"...\" }],\n  \"companies\": [{ \"name\": \"...\" }],\n  \"locations\": [{ \"name\": \"...\" }],\n  \"tools\": [{ \"name\": \"...\" }],\n  \"concepts\": [{ \"name\": \"...\" }]\n}\n```"
  },
  {
    "name": "file_parser",
    "user": "system",
    "prompt": "# R√îLE ET OBJECTIF\nTu es un assistant IA expert en analyse de documents professionnels. Ta mission est d'analyser un texte brut (`file_text`) et de le classifier dans l'une des trois cat√©gories suivantes : 'profile' (CV), 'company' (description d'entreprise), ou 'post' (autre document, article, etc.).\n\n# INSTRUCTIONS\n1.  Analyse le texte pour identifier sa structure.\n2.  Si le texte est un CV, classifie-le comme `\"category\": \"profile\"` et extrais son contenu.\n3.  Si le texte est une description d'entreprise (plaquette, '√† propos', ...), classifie-le comme `\"category\": \"company\"` et extrais son contenu.\n4.  Sinon, classifie-le comme `\"category\": \"post\"`.\n\n# R√àGLES D'EXTRACTION (SI 'profile')\n-   `name`: Le nom complet du candidat.\n-   `headline`: Le titre de poste le plus r√©cent.\n-   `about`: Le r√©sum√© de carri√®re.\n-   `experience`: Tableau d'objets (title, company, location, start_date, end_date, description).\n-   `education`: Tableau d'objets (title, degree, field).\n\n# R√àGLES D'EXTRACTION (SI 'company')\n-   `name`: Le nom complet de l'entreprise.\n-   `about`: La description '√Ä propos', 'Mission' ou 'R√©sum√©'.\n-   `industries`: Le secteur d'activit√© (ex: \"Logiciel\").\n-   `company_size`: La taille (ex: \"1001-5000 employ√©s\").\n-   `locations`: Le si√®ge social ou les bureaux (ex: \"Paris, France\").\n-   `updates`: **[IMPORTANT]** Un tableau d'objets. Tente d'extraire les sections d'actualit√©s, les 'projets cl√©s', ou les annonces dat√©es. Chaque objet doit avoir :\n    -   `date`: La date de l'annonce si trouv√©e (ex: \"juin 2024\"). Sinon, `null`.\n    -   `text`: Le texte complet de l'annonce ou de la section.\n    -   `likes_count`: 0 (par d√©faut pour les fichiers manuels).\n\n# STRUCTURE DE SORTIE FINALE\nLa sortie doit √™tre **uniquement et exclusivement un objet JSON valide**.\n\n## EXEMPLE DE SORTIE (COMPANY)\n```json\n{\n  \"category\": \"company\",\n  \"pageContent\": {\n    \"name\": \"Tech Solutions Inc.\",\n    \"about\": \"Tech Solutions Inc. est un leader mondial...\",\n    \"industries\": \"Logiciels d'entreprise\",\n    \"company_size\": \"1001-5000 employ√©s\",\n    \"locations\": \"Paris, France\",\n    \"updates\": [\n      {\n        \"date\": \"juin 2024\",\n        \"text\": \"Lancement de notre nouvelle plateforme 'Quantum'. Elle vise √† r√©volutionner l'analyse de donn√©es...\",\n        \"likes_count\": 0\n      },\n      {\n        \"date\": null,\n        \"text\": \"Projet Cl√© 'Phoenix' : Nous avons finalis√© le d√©ploiement de notre infrastructure cloud...\",\n        \"likes_count\": 0\n      }\n    ]\n  }\n}\n```\n\n## EXEMPLE DE SORTIE (PROFILE)\n```json\n{\n  \"category\": \"profile\",\n  \"pageContent\": { ... } \n}\n```\n\n## EXEMPLE DE SORTIE (POST)\n```json\n{\n  \"category\": \"post\"\n}\n```",
    "description": "OUTIL D'ANALYSE INITIALE. √Ä utiliser EN PREMIER pour classifier le document (Profile/CV, Company, Post) et extraire la structure de base."
  },
  {
    "name": "graph_extraction",
    "user": "system",
    "prompt": "Tu es un expert en Knowledge Graph. Ta mission est d'extraire des relations s√©mantiques pr√©cises du texte fourni.\n\nFormat de sortie JSON attendu :\n{\n  \"triplets\": [\n    {\n      \"source\": \"Nom Entit√© 1\",\n      \"source_type\": \"PERSON | COMPANY | CONCEPT | EVENT | TOOL | LOCATION\",\n      \"relation\": \"VERBE_EN_MAJUSCULE_ET_ANGLAIS\", \n      \"target\": \"Nom Entit√© 2\",\n      \"target_type\": \"PERSON | COMPANY | CONCEPT | EVENT | TOOL | LOCATION\",\n      \"description\": \"Court contexte (ex: 'Depuis 2020')\"\n    }\n  ]\n}\n\nR√®gles :\n1. Utilise des relations pr√©cises : ACQUIRED, SUED, PARTNERED_WITH, AUTHORED, ATTACKED_BY, CEO_OF, LOCATED_IN. √âvite les relations vagues comme \"LINKED_TO\".\n2. Normalise les noms (ex: \"Microsoft Corp\" -> \"Microsoft\").\n3. Si le texte parle d'une attaque informatique, extrais : ATTACKER, VICTIM, METHOD, DATE.\n4. Extrais au maximum 15 triplets les plus pertinents.\n\nREGLE STRICTE: toujours r√©pondre en fran√ßais"
  }
]

def seed_prompts():
    print("üöÄ Initialisation des Prompts (Seed)...")
    
    # S'assurer que la table existe
    Base.metadata.create_all(bind=engine)
    
    count = 0
    for p_data in RAW_PROMPTS_DATA:
        try:
            # On ignore l'ID Mongo (_id) s'il est pr√©sent, on laisse SQLite g√©rer
            prompt_in = PromptCreate(
                name=p_data["name"],
                prompt=p_data["prompt"],
                user=p_data["user"],
                description=p_data.get("description")
            )
            prompt_repository.upsert_prompt(prompt_in)
            count += 1
            print(f"‚úÖ Prompt trait√© : {p_data['name']}")
        except Exception as e:
            print(f"‚ùå Erreur sur {p_data.get('name')}: {e}")

    print(f"\nüéâ Termin√© ! {count} prompts sont maintenant en base SQLite.")

if __name__ == "__main__":
    seed_prompts()

# ------------------------------------------
# FICHIER : scripts\test_01_check_state.py
# ------------------------------------------
import sys
import os
import requests
from sqlalchemy.orm import Session

# Ajout du dossier parent au path pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine, get_chroma_client
from database.models import PromptModel, LoginModel, DocModel

# Liste des prompts critiques pour que le RAG fonctionne
REQUIRED_PROMPTS = ["synthesis_tags", "chunk_hypothetical_questions", "chunk_entities", "graph_extraction"]

def check_system_state():
    print("üîç [DIAGNOSTIC] V√©rification de l'√©tat du syst√®me...\n")
    
    with Session(engine) as db:
        # 1. V√©rification des Prompts (CRITIQUE)
        print("1Ô∏è‚É£  V√©rification des Prompts...")
        existing_prompts = [p.name for p in db.query(PromptModel).all()]
        missing = [p for p in REQUIRED_PROMPTS if p not in existing_prompts]
        
        if missing:
            print(f"   ‚ùå ALERTE : Il manque ces prompts critiques : {missing}")
            print("      -> Lancez 'python scripts/seed_prompts.py' si vous les avez perdus.")
        else:
            print(f"   ‚úÖ {len(existing_prompts)} prompts trouv√©s (dont les {len(REQUIRED_PROMPTS)} critiques).")

        # 2. V√©rification des Docs (Doit √™tre vide ou presque)
        count_docs = db.query(DocModel).count()
        print(f"\n2Ô∏è‚É£  V√©rification des Documents : {count_docs} documents en base SQLite.")

    # 3. V√©rification ChromaDB
    print("\n3Ô∏è‚É£  V√©rification ChromaDB (Vecteurs)...")
    try:
        client = get_chroma_client()
        coll = client.get_or_create_collection("rag_chunks")
        count_vectors = coll.count()
        print(f"   ‚úÖ Connexion Chroma OK. Contient {count_vectors} chunks.")
    except Exception as e:
        print(f"   ‚ùå ERREUR CHROMA : {e}")

    print("\nüèÅ Diagnostic termin√©.")

if __name__ == "__main__":
    check_system_state()

# ------------------------------------------
# FICHIER : scripts\test_02_full_flow.py
# ------------------------------------------
import requests
import time
import sys
import json

# Configuration
API_URL = "http://127.0.0.1:8000"
TEST_USER = "admin_test"
TEST_DOC_TEXT = "Le projet secret s'appelle 'Projet Omega'. Il vise √† cr√©er une IA quantique d'ici 2030."

def run_test():
    print(f"üöÄ D√©marrage du Test Fonctionnel sur {API_URL}...\n")

    # ---------------------------------------------------------
    # 1. INGESTION (On pousse la donn√©e)
    # ---------------------------------------------------------
    print("üîπ [ETAPE 1] Ingestion du document...")
    try:
        res = requests.post(f"{API_URL}/ingest/text", json={
            "text": TEST_DOC_TEXT,
            "tags": ["test", "secret"],
            "employee": TEST_USER
        })
        if res.status_code != 200:
            print(f"   ‚ùå Erreur API Ingest ({res.status_code}) : {res.text}")
            return
        
        data = res.json()
        print(f"   ‚úÖ Ingestion OK. ID: {data.get('doc_id')} | Chunks cr√©√©s: {data.get('chunks_count')}")
        
        if data.get('chunks_count') == 0:
            print("   ‚ö†Ô∏è  ATTENTION : 0 chunks cr√©√©s ! V√©rifiez 'services/chunking/manager.py'.")
            return

    except Exception as e:
        print(f"   ‚ùå Exception critique : {e}")
        return

    print("   ‚è≥ Attente de 2 secondes pour l'indexation...")
    time.sleep(2)

    # ---------------------------------------------------------
    # 2. VERIFICATION SEARCH (On v√©rifie la pr√©sence physique)
    # ---------------------------------------------------------
    print("\nüîπ [ETAPE 2] V√©rification Vectorielle (Search)...")
    try:
        # On utilise la route /search que vous avez ajout√©e dans api.py
        res = requests.post(f"{API_URL}/search/", json={
            "query": "Omega",
            "limit": 3,
            "employee": TEST_USER
        })
        
        if res.status_code == 200:
            results = res.json().get("results", [])
            found = False
            for r in results:
                if "Omega" in r.get("content", ""):
                    print(f"   ‚úÖ Contenu retrouv√© dans Chroma ! (Score: {r.get('score_distance')})")
                    print(f"      Extrait : {r.get('content')[:50]}...")
                    found = True
                    break
            
            if not found:
                print("   ‚ùå ECHEC : Le document n'est pas remont√© par la recherche vectorielle.")
                print(f"      R√©sultats bruts : {json.dumps(results, indent=2)}")
                return
        else:
            print(f"   ‚ùå Erreur API Search ({res.status_code}) : {res.text}")
            return

    except Exception as e:
        print(f"   ‚ùå Erreur lors du test Search : {e}")
        return

    # ---------------------------------------------------------
    # 3. TEST CHAT (On teste l'intelligence)
    # ---------------------------------------------------------
    print("\nüîπ [ETAPE 3] Test du Chat (RAG)...")
    question = "Quel est le nom du projet secret et son but ?"
    try:
        res = requests.post(f"{API_URL}/chat/", json={
            "question": question,
            "employee": TEST_USER
        })
        
        if res.status_code == 200:
            answer = res.json().get("answer", "")
            sources = res.json().get("sources", [])
            
            print(f"   ‚ùì Question : {question}")
            print(f"   ü§ñ R√©ponse  : {answer}\n")
            
            if "Omega" in answer:
                print("   üéâ SUCC√àS TOTAL : Le syst√®me fonctionne de bout en bout !")
            else:
                print("   üî∏ RESULTAT MITIG√â : Le document est trouv√© mais le LLM ne l'a pas utilis√©.")
                print("      -> V√©rifiez le Prompt Syst√®me dans 'services/chat.py'.")
        else:
            print(f"   ‚ùå Erreur API Chat ({res.status_code}) : {res.text}")

    except Exception as e:
        print(f"   ‚ùå Erreur lors du test Chat : {e}")

if __name__ == "__main__":
    run_test()

# ------------------------------------------
# FICHIER : scripts\test_master.py
# ------------------------------------------
import requests
import time
import os
import sys

# Configuration
API_URL = "http://127.0.0.1:8000"
EMPLOYEE_ID = "admin_test_master"

# Codes couleurs pour la lisibilit√©
GREEN = "\033[92m"
RED = "\033[91m"
RESET = "\033[0m"

def log(step, success, message):
    icon = "‚úÖ" if success else "‚ùå"
    color = GREEN if success else RED
    print(f"{color}{icon} [{step}] {message}{RESET}")
    if not success:
        print(f"{RED}   -> ARR√äT CRITIQUE : Corrigez cette √©tape avant de continuer.{RESET}")
        sys.exit(1)

def create_dummy_pdf():
    filename = "test_doc.pdf"
    with open(filename, "wb") as f:
        f.write(b"%PDF-1.4\n1 0 obj\n<< /Type /Catalog /Pages 2 0 R >>\nendobj\n2 0 obj\n<< /Type /Pages /Kids [3 0 R] /Count 1 >>\nendobj\n3 0 obj\n<< /Type /Page /Parent 2 0 R /Resources << >> /MediaBox [0 0 612 792] /Contents 4 0 R >>\nendobj\n4 0 obj\n<< /Length 50 >>\nstream\nBT /F1 12 Tf 72 720 Td (Ceci est un test PDF pour le RAG.) Tj ET\nendstream\nendobj\nxref\n0 5\n0000000000 65535 f \n0000000010 00000 n \n0000000060 00000 n \n0000000157 00000 n \n0000000296 00000 n \ntrailer\n<< /Size 5 /Root 1 0 R >>\nstartxref\n400\n%%EOF")
    return filename

def run_tests():
    print(f"\nüöÄ D√âMARRAGE BATTERIE DE TESTS SUR {API_URL}\n")

    # ---------------------------------------------------------
    # 1. TEST CONNEXION (Healthcheck)
    # ---------------------------------------------------------
    try:
        r = requests.get(f"{API_URL}/")
        log("API", r.status_code == 200, f"API en ligne (Ping: {r.json().get('status')})")
    except Exception as e:
        log("API", False, f"Impossible de joindre l'API. Lancez 'python -m api.main'. Erreur: {e}")

    # ---------------------------------------------------------
    # 2. TEST INGESTION TEXTE (Route: POST /ingest/text)
    # ---------------------------------------------------------
    print("\nüîπ TEST 2 : Ingestion Texte")
    payload_text = {
        "text": "Le projet Apollo 11 a permis √† l'homme de marcher sur la Lune en 1969.",
        "tags": ["espace", "histoire"],
        "employee": EMPLOYEE_ID
    }
    r = requests.post(f"{API_URL}/ingest/text", json=payload_text)
    
    if r.status_code == 200:
        data = r.json()
        log("INGEST_TEXT", True, f"Doc ID: {data.get('doc_id')} | Chunks: {data.get('chunks_count')}")
    else:
        log("INGEST_TEXT", False, f"Erreur {r.status_code}: {r.text}")

    # ---------------------------------------------------------
    # 3. TEST INGESTION URL (Route: POST /ingest/url)
    # ---------------------------------------------------------
    print("\nüîπ TEST 3 : Ingestion URL")
    # URL Wikip√©dia simple pour √©viter les blocages
    payload_url = {
        "url": "https://fr.wikipedia.org/wiki/Lune",
        "tags": ["wiki", "espace"],
        "employee": EMPLOYEE_ID
    }
    r = requests.post(f"{API_URL}/ingest/url", json=payload_url)

    if r.status_code == 200:
        data = r.json()
        log("INGEST_URL", True, f"Doc ID: {data.get('doc_id')} | Chunks: {data.get('chunks_count')}")
    else:
        # On tol√®re l'√©chec si Tavily n'est pas configur√©, mais on le signale
        if "TAVILY_API_KEY" not in os.environ and "400" in str(r.status_code):
             print(f"{RED}‚ö†Ô∏è  Echec URL : V√©rifiez votre TAVILY_API_KEY dans .env{RESET}")
        else:
            log("INGEST_URL", False, f"Erreur {r.status_code}: {r.text}")

    # ---------------------------------------------------------
    # 4. TEST INGESTION FICHIER (Route: POST /ingest/file)
    # ---------------------------------------------------------
    print("\nüîπ TEST 4 : Ingestion Fichier (Upload)")
    pdf_name = create_dummy_pdf()
    try:
        with open(pdf_name, "rb") as f:
            files = {"file": (pdf_name, f, "application/pdf")}
            data = {"tags": "pdf,test", "employee": EMPLOYEE_ID}
            r = requests.post(f"{API_URL}/ingest/file", files=files, data=data)
        
        if r.status_code == 200:
            res_json = r.json()
            log("INGEST_FILE", True, f"Doc ID: {res_json.get('doc_id')}")
        else:
            log("INGEST_FILE", False, f"Erreur {r.status_code}: {r.text}")
    finally:
        if os.path.exists(pdf_name):
            os.remove(pdf_name)

    print("‚è≥ Pause 2s pour indexation ChromaDB...")
    time.sleep(2)

    # ---------------------------------------------------------
    # 5. TEST RECHERCHE (Route: POST /search/)
    # ---------------------------------------------------------
    print("\nüîπ TEST 5 : Recherche Vectorielle (Debug)")
    payload_search = {
        "query": "Apollo 11",
        "limit": 3,
        "employee": EMPLOYEE_ID
    }
    r = requests.post(f"{API_URL}/search/", json=payload_search)
    
    if r.status_code == 200:
        results = r.json().get("results", [])
        if results and len(results) > 0:
            log("SEARCH", True, f"Trouv√© : {results[0]['content'][:50]}... (Score: {results[0]['score_distance']})")
        else:
            log("SEARCH", False, "Aucun r√©sultat trouv√© (Indexation √©chou√©e ?)")
    else:
        log("SEARCH", False, f"Erreur {r.status_code}: {r.text}")

    # ---------------------------------------------------------
    # 6. TEST CHAT (Route: POST /chat/)
    # ---------------------------------------------------------
    print("\nüîπ TEST 6 : Chat RAG")
    payload_chat = {
        "question": "Quand l'homme a-t-il march√© sur la Lune ?",
        "employee": EMPLOYEE_ID
    }
    r = requests.post(f"{API_URL}/chat/", json=payload_chat)

    if r.status_code == 200:
        ans = r.json()
        response_text = ans.get("answer", "")
        sources = ans.get("sources", [])
        print(f"   ü§ñ R√©ponse : {response_text}")
        print(f"   üìö Sources : {sources}")
        
        if "1969" in response_text or "Apollo" in response_text:
            log("CHAT", True, "R√©ponse coh√©rente avec le contexte.")
        else:
            print(f"{RED}‚ö†Ô∏è  R√©ponse IA faible (V√©rifiez le prompt ou le mod√®le Ollama).{RESET}")
            # On ne bloque pas ici, car techniquement l'API a r√©pondu
    else:
        log("CHAT", False, f"Erreur {r.status_code}: {r.text}")

    print(f"\n{GREEN}üéâ BATTERIE DE TESTS TERMIN√âE AVEC SUCC√àS !{RESET}")
    print("Votre API Python fonctionne parfaitement.")

if __name__ == "__main__":
    run_tests()

# ------------------------------------------
# FICHIER : scripts\validate_chunking_profile.py
# ------------------------------------------
import sys
import os
import time
import logging

# Config logs
logging.basicConfig(level=logging.INFO)

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from services.chat import chat_service

def run_profile_test():
    print("üöÄ D√©marrage Test Chunking (Profil Structur√©)...")
    Base.metadata.create_all(bind=engine)
    
    employee_id = "recruiter_bob"
    
    # 1. Donn√©e structur√©e (Comme si elle venait d'un scraping LinkedIn)
    fake_profile = {
        "name": "Alice Wonderland",
        "about": "Experte en Data Science passionn√©e par les lapins blancs.",
        "experience": [
            {
                "title": "Lead Data Scientist",
                "company": "Wonder Corp",
                "date_range": "2020 - Present",
                "description": "Gestion de l'√©quipe IA, d√©ploiement de mod√®les LLM."
            },
            {
                "title": "Junior Analyst",
                "company": "Rabbit Hole Inc",
                "date_range": "2018 - 2020",
                "description": "Analyse de donn√©es temporelles."
            }
        ],
        "education": [
            {
                "school": "University of Hearts",
                "degree": "Master in Magic"
            }
        ]
    }

    # 2. Ingestion (on passe le dict direct)
    print("\n--- [1] Ingestion du Profil JSON ---")
    result = ingestion_service.process_input(
        input_data=fake_profile,
        employee=employee_id,
        tags=["candidat", "data"],
        origin="api_push"
    )
    
    print(f"‚úÖ Ingestion termin√©e.")
    print(f"   Strat√©gie utilis√©e : {result['strategy']}")
    print(f"   Chunks cr√©√©s : {result['chunks_count']}")
    
    # On attend 3 chunks logiques : 1 About + 2 Experiences + 1 Education = 4 chunks
    # (Ou 3 si about est petit)
    
    time.sleep(1)

    # 3. Chat (V√©rification RAG)
    print("\n--- [2] Question sur le CV ---")
    # On pose une question pr√©cise sur une exp√©rience
    question = "Qu'a fait Alice chez Rabbit Hole Inc ?"
    
    answer = chat_service.chat(question, employee_id)
    
    print(f"ü§ñ R√©ponse IA :\n{answer['response']}")
    print(f"üìö Sources : {answer['sources']}")

if __name__ == "__main__":
    run_profile_test()

# ------------------------------------------
# FICHIER : scripts\validate_enrichment.py
# ------------------------------------------
import sys
import os
import logging
import json

# Config logs
logging.basicConfig(level=logging.INFO)

# Ajout du dossier parent au path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# CORRECTION ICI : On importe engine et Base au lieu de init_db
from database.connection import engine
from database.models import Base
from services.chunking.enrichment import enrichment_service

def run_enrichment_test():
    print("üöÄ D√©marrage Test Enrichissement LLM...")
    
    # CORRECTION ICI : Initialisation explicite via SQLAlchemy
    Base.metadata.create_all(bind=engine)

    # 1. Texte "About" type LinkedIn
    about_text = """
    D√©veloppeur Full Stack avec 5 ans d'exp√©rience. 
    Expert en Python, FastAPI et React. 
    J'ai g√©r√© des projets cloud sur AWS et Azure. 
    Je suis reconnu pour ma capacit√© √† r√©soudre des probl√®mes complexes et mon esprit d'√©quipe.
    Certifi√© AWS Solutions Architect.
    """

    print(f"\n--- Texte √† analyser ---\n{about_text.strip()}\n")

    # 2. Appel du service (utilise le prompt 'chunk_about' en base)
    try:
        print("‚è≥ Appel au LLM (Ollama) via EnrichmentService...")
        metadata = enrichment_service.extract_metadata(about_text, "chunk_about")
        
        print("\n‚úÖ R√©sultat Structur√© (JSON) :")
        print("-" * 30)
        print(json.dumps(metadata, indent=2, ensure_ascii=False))
        print("-" * 30)

        # V√©rifications
        if metadata and ("hard_skills" in metadata or "technologies" in metadata):
            print("üéâ SUCC√àS : Des comp√©tences ont √©t√© extraites !")
        else:
            print("‚ö†Ô∏è AVERTISSEMENT : Le JSON est valide mais vide. V√©rifiez que le prompt 'chunk_about' est bien en base (seed_prompts.py).")

    except Exception as e:
        print(f"‚ùå ERREUR : {e}")

if __name__ == "__main__":
    run_enrichment_test()

# ------------------------------------------
# FICHIER : scripts\validate_ingest_file.py
# ------------------------------------------
import sys
import os
import time
from dotenv import load_dotenv
from fpdf import FPDF # Pour g√©n√©rer un PDF de test rapidement

# pip install fpdf (juste pour ce script de test) ou cr√©ez un fichier manuellement

load_dotenv()
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from services.chat import chat_service

def create_dummy_pdf(filename):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt="RAPPORT CONFIDENTIEL - PROJET ORION", ln=1, align="C")
    pdf.cell(200, 10, txt="1. Le budget allou√© est de 50 millions d'euros.", ln=2)
    pdf.cell(200, 10, txt="2. Le directeur du projet est M. Vector.", ln=3)
    pdf.output(filename)
    print(f"üìÑ PDF de test g√©n√©r√© : {filename}")

def run_file_test():
    print("üöÄ D√©marrage Test Ingestion FICHIER (PDF)...")
    Base.metadata.create_all(bind=engine)
    employee_id = "file_tester"
    
    # 1. G√©n√©ration d'un fichier PDF local
    pdf_path = "test_projet_orion.pdf"
    try:
        create_dummy_pdf(pdf_path)
    except ImportError:
        print("‚ö†Ô∏è 'fpdf' manquant. Installez-le (pip install fpdf) ou cr√©ez 'test_projet_orion.pdf' manuellement.")
        return

    # 2. Ingestion
    print(f"\n--- [1] Ingestion du fichier : {pdf_path} ---")
    try:
        # On passe le CHEMIN du fichier
        result = ingestion_service.process_input(
            input_data=pdf_path,
            employee=employee_id,
            tags=["projet", "finance"],
            origin="filesystem"
        )
        print(f"‚úÖ Ingestion Fichier r√©ussie !")
        print(f"   Source d√©tect√©e : {result['source']}")
        print(f"   Doc ID : {result['doc_id']}")
    except Exception as e:
        print(f"‚ùå Erreur : {e}")
        return

    # Pause Indexation
    time.sleep(1)

    # 3. Chat
    print("\n--- [2] V√©rification RAG sur le PDF ---")
    question = "Quel est le budget du projet Orion et qui est le directeur ?"
    
    answer = chat_service.chat(question, employee_id)
    
    print(f"ü§ñ R√©ponse IA :\n{answer['response']}")
    print(f"üìö Sources : {answer['sources']}")

    # Nettoyage
    if os.path.exists(pdf_path):
        os.remove(pdf_path)

if __name__ == "__main__":
    run_file_test()

# ------------------------------------------
# FICHIER : scripts\validate_ingest_url.py
# ------------------------------------------
import sys
import os
import time
import logging # <--- Import n√©cessaire

# Configuration des logs pour voir ce que dit Tavily
logging.basicConfig(level=logging.INFO)

# Ajout du dossier parent au path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from services.chat import chat_service

def run_url_test():
    print("üöÄ D√©marrage Test Ingestion URL (Tavily)...")
    
    # Init DB
    Base.metadata.create_all(bind=engine)

    employee_id = "web_tester"
    
    # URL de test : On utilise Wikip√©dia pour valider la connexion API (plus fiable que TDS)
    target_url = "https://fr.wikipedia.org/wiki/Intelligence_artificielle" 

    print(f"\n--- [1] Tentative d'ingestion de : {target_url} ---")
    try:
        # On appelle la nouvelle m√©thode unifi√©e 'process_input'
        result = ingestion_service.process_input(
            input_data=target_url,
            employee=employee_id,
            tags=["ia", "wiki", "web"],
            origin="test_script"
        )
        print(f"‚úÖ Ingestion Web r√©ussie !")
        print(f"   Source : {result['source']}")
        print(f"   Chunks : {result['chunks_count']}")
        
    except Exception as e:
        print(f"‚ùå Erreur critique : {e}")
        # On ne quitte pas, on veut voir les logs au dessus
        return

    # Pause pour l'indexation Chroma
    time.sleep(2)

    print("\n--- [2] V√©rification RAG sur le contenu Web ---")
    question = "C'est quoi l'intelligence artificielle ?"
    
    answer = chat_service.chat(question, employee_id)
    
    print(f"ü§ñ R√©ponse IA :\n{answer['response']}")
    print(f"üìö Sources : {answer['sources']}")

if __name__ == "__main__":
    run_url_test()

# ------------------------------------------
# FICHIER : scripts\validate_step1.py
# ------------------------------------------
import sys
import os

# Ajout du dossier parent au path pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine, get_db
from database.models import Base, LoginModel, DocModel
from schemas.user import LoginCreate, LoginResponse
from schemas.doc import DocCreate

def run_validation():
    print("üöÄ D√©marrage de la validation √âtape 1 (Database & Schemas)...")

    # 1. Cr√©ation des Tables (Test des Models)
    print("\n--- [1] Initialisation SQLite ---")
    try:
        Base.metadata.create_all(bind=engine)
        print("‚úÖ Tables cr√©√©es avec succ√®s (logins, docs, api_logs).")
    except Exception as e:
        print(f"‚ùå Erreur cr√©ation tables: {e}")
        return

    # 2. Insertion de donn√©es (Test Session + Models)
    print("\n--- [2] Test Insertion SQL ---")
    db = next(get_db())
    
    # Nettoyage pr√©ventif
    db.query(LoginModel).filter(LoginModel.employee == "test_dev").delete()
    db.commit()

    try:
        new_user = LoginModel(
            employee="cv@duhamel.xyz",
            company="Local Corp",
            lastname="Dev",
            firstname="Junior",
            password="admin1",
            services={"graph_rag": True}
        )
        db.add(new_user)
        db.commit()
        db.refresh(new_user)
        print(f"‚úÖ User ins√©r√© en DB: ID={new_user.id}, Services={new_user.services}")
    except Exception as e:
        print(f"‚ùå Erreur insertion SQL: {e}")
        return

    # 3. Validation Pydantic (Test Schemas -> Model -> Schema)
    print("\n--- [3] Test Validation Pydantic ---")
    try:
        # Conversion Model SQL -> Schema Pydantic
        user_schema = LoginResponse.model_validate(new_user)
        print(f"‚úÖ Conversion SQL->Pydantic r√©ussie: {user_schema.employee} (Pass masqu√©)")
        
        # Test Doc Schema
        doc_data = DocCreate(
            doc="https://linkedin.com/in/test",
            category="profile",
            source="linkedin",
            origin="extension",
            tags=["test"],
            employee="test_dev",
            job_id="job_123",
            page_content={"name": "Test Profile", "skills": ["Python"]}
        )
        print(f"‚úÖ Schema Doc valide: {doc_data.doc}")
        
    except Exception as e:
        print(f"‚ùå Erreur validation Pydantic: {e}")
        return

    print("\nüéâ √âTAPE 1 TERMIN√âE AVEC SUCC√àS : Structure propre et modulaire valid√©e.")

if __name__ == "__main__":
    run_validation()

# ------------------------------------------
# FICHIER : scripts\validate_step2.py
# ------------------------------------------
import sys
import os

# Path hack pour les imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from schemas.user import LoginCreate
from schemas.doc import DocCreate, Chunk as ChunkSchema
from repositories.user import user_repository
from repositories.doc import doc_repository
from repositories.chunk import chunk_repository

def run_validation():
    print("üöÄ D√©marrage Validation √âtape 2 (Repositories)...")

    # 1. Reset DB
    Base.metadata.drop_all(bind=engine)
    Base.metadata.create_all(bind=engine)
    print("‚úÖ DB Reset OK.")

    # 2. Cr√©ation User
    print("\n--- [User Repo] ---")
    user = user_repository.create_user(LoginCreate(
        employee="jean.dupont@local.fr",
        company="MyLocalCorp",
        lastname="Dupont",
        firstname="Jean",
        password="secret_pass",
        credit=100
    ))
    print(f"‚úÖ User cr√©√©: {user.firstname} {user.lastname}")

    # 3. Cr√©ation Doc (M√©tadonn√©es)
    print("\n--- [Doc Repo] ---")
    doc_data = DocCreate(
        doc="https://fr.wikipedia.org/wiki/Python_(langage)",
        category="wiki",
        source="web",
        origin="import",
        tags=["tech", "python"],
        employee="jean.dupont@local.fr",
        job_id="job_1",
        page_content={"title": "Python Langage", "summary": "Langage de programmation interpr√©t√©."}
    )
    doc = doc_repository.upsert_doc(doc_data)
    print(f"‚úÖ Doc ins√©r√© (SQLite): {doc.doc} (Status: {doc.status})")

    # 4. Ajout Chunks (Vecteurs)
    print("\n--- [Chunk Repo] ---")
    chunks = [
        ChunkSchema(
            content="Python est un langage de programmation interpr√©t√©, multi-paradigme et multiplateformes.",
            metadata={"type": "intro", "page": 1}
        ),
        ChunkSchema(
            content="Il favorise la programmation imp√©rative structur√©e, fonctionnelle et orient√©e objet.",
            metadata={"type": "details", "page": 1}
        )
    ]
    chunk_repository.add_chunks(doc.doc, doc.employee, chunks)
    
    # 5. Test Recherche
    print("\n--- [Search Test] ---")
    results = chunk_repository.search("programmation objet", "jean.dupont@local.fr", limit=1)
    
    if results['documents'] and len(results['documents'][0]) > 0:
        found_text = results['documents'][0][0]
        print(f"‚úÖ Recherche S√©mantique OK.\n   Question: 'programmation objet'\n   Trouv√©: '{found_text}'")
    else:
        print("‚ùå Echec de la recherche s√©mantique.")

if __name__ == "__main__":
    run_validation()

# ------------------------------------------
# FICHIER : scripts\validate_step3.py
# ------------------------------------------
import sys
import os
import time

# Path hack
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from services.chat import chat_service
from repositories.doc import doc_repository

def run_validation():
    print("üöÄ D√©marrage Validation √âtape 3 (Services)...")
    
    # 1. Initialisation de la DB (Correction ici : on utilise engine direct)
    Base.metadata.create_all(bind=engine)
    print("‚úÖ DB Initialis√©e.")

    employee_id = "tester@local.com"
    doc_name = "procedure_securite.txt"
    
    # 2. Texte de test (Contenu m√©tier)
    content = """
    PROC√âDURE DE S√âCURIT√â - CODE ROUGE
    1. En cas d'incendie, ne prenez pas l'ascenseur.
    2. Le point de rassemblement est le Parking Sud, Zone B.
    3. Le code du coffre-fort des serveurs est 'K9-Alpha-77'.
    4. Le responsable de la s√©curit√© est Mme Martin (poste 404).
    """

    # 3. Test Ingestion
    print(f"\n--- [1] Ingestion du document : {doc_name} ---")
    try:
        result = ingestion_service.process_text_document(
            doc_id=doc_name,
            text_content=content,
            employee=employee_id,
            tags=["s√©curit√©", "interne"],
            origin="upload"
        )
        print(f"‚úÖ Ingestion termin√©e. Chunks cr√©√©s : {result['chunks_count']}")
    except Exception as e:
        print(f"‚ùå Erreur Ingestion: {e}")
        return
    
    # V√©rification du statut en base
    doc_in_db = doc_repository.get_doc(doc_name, employee_id)
    if doc_in_db:
        print(f"   Statut en DB : {doc_in_db.status}")
    else:
        print("‚ùå Erreur: Document non trouv√© en base SQLite apr√®s ingestion.")

    # Petite pause pour laisser Chroma indexer
    time.sleep(1)

    # 4. Test Chat (RAG)
    print("\n--- [2] Test du Chat RAG ---")
    question = "Quel est le code du coffre et o√π est le point de rassemblement ?"
    print(f"‚ùì Question : {question}")
    
    try:
        chat_result = chat_service.chat(question, employee_id)
        
        print("\nü§ñ R√©ponse de l'IA :")
        print("-" * 40)
        print(chat_result['response'])
        print("-" * 40)
        print(f"üìö Sources utilis√©es : {chat_result['sources']}")

        # Validation simple du contenu
        if "K9-Alpha-77" in chat_result['response'] or "Parking Sud" in chat_result['response']:
            print("\nüéâ √âTAPE 3 VALID√âE : Le RAG complet fonctionne !")
        else:
            print("\n‚ö†Ô∏è ATTENTION : L'IA n'a pas donn√© la r√©ponse attendue. V√©rifiez que Ollama tourne bien.")
            
    except Exception as e:
        print(f"‚ùå Erreur Chat: {e}")

if __name__ == "__main__":
    run_validation()

# ------------------------------------------
# FICHIER : scripts\verify_chunking_parity.py
# ------------------------------------------
import sys
import os
import time
import logging

logging.basicConfig(level=logging.INFO)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from repositories.doc import doc_repository
from repositories.chunk import chunk_repository

def verify_parity():
    print("üöÄ D√©marrage V√©rification Parit√© Node.js -> Python...")
    Base.metadata.create_all(bind=engine)
    
    employee_id = "parity_checker"

    # CAS 1 : Test du Post LinkedIn (Doit utiliser PostStrategy)
    post_text = """
    J'ai le plaisir d'annoncer que je rejoins OpenAI en tant que Lead Researcher.
    Apr√®s 5 ans chez Google DeepMind, c'est une nouvelle aventure qui commence !
    #AI #Career #NewJob
    """
    
    print("\n--- [1] Ingestion d'un Post LinkedIn ---")
    res_post = ingestion_service.process_input(
        input_data={"post_text": post_text}, # Format dict pour simuler structure
        employee=employee_id,
        tags=["news"],
        origin="linkedin_import"
    )
    
    # On force la cat√©gorie 'post' car process_input d√©tecte 'raw' par d√©faut pour les dicts
    # Note: Dans une vraie app, le routeur de cat√©gorie ferait ce travail.
    # Ici, pour le test, on va v√©rifier si le 'synthesis' a fonctionn√©.

    # V√©rification Synth√®se
    doc_db = doc_repository.get_doc(res_post['doc_id'], employee_id)
    print(f"üìÑ Doc sauvegard√© : {doc_db.doc}")
    print(f"   Synth√®se g√©n√©r√©e : {doc_db.synthesis[:100]}...") # Doit ne pas √™tre vide
    print(f"   Tags sugg√©r√©s : {doc_db.suggested_tags}")

    if doc_db.synthesis:
        print("‚úÖ SUCC√àS : La synth√®se automatique (synthesis_tags) fonctionne !")
    else:
        print("‚ùå √âCHEC : Pas de synth√®se g√©n√©r√©e.")

    # CAS 2 : V√©rification des m√©tadonn√©es du Chunk
    # On cherche les chunks de ce doc
    chunks = chunk_repository.search("OpenAI", employee_id)
    if chunks and chunks['metadatas'] and len(chunks['metadatas'][0]) > 0:
        meta = chunks['metadatas'][0][0]
        # On v√©rifie si PostStrategy a bien tourn√© (elle ajoute le type 'post')
        print(f"üì¶ Metadata du Chunk : {meta}")
        if meta.get("type") == "post":
            print("‚úÖ SUCC√àS : PostStrategy utilis√©e correctement.")
        else:
            print(f"‚ö†Ô∏è ATTENTION : Type de chunk inattendu ({meta.get('type')}).")

if __name__ == "__main__":
    verify_parity()

# ------------------------------------------
# FICHIER : scripts\verify_entities.py
# ------------------------------------------
import sys
import os
import logging
import json

logging.basicConfig(level=logging.INFO)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from repositories.chunk import chunk_repository

def run_entity_test():
    print("üöÄ Test: Extraction d'Entit√©s (NER)...")
    Base.metadata.create_all(bind=engine)
    
    # Texte riche en entit√©s
    text = """
    Hier, Satya Nadella, le CEO de Microsoft, a annonc√© un partenariat avec Mistral AI.
    L'accord a √©t√© sign√© √† Paris en pr√©sence de Brad Smith.
    Ils vont int√©grer leurs mod√®les dans Azure AI Studio pour concurrencer Google.
    """
    
    doc_id = "test_ner_microsoft"
    employee_id = "tester_ner"

    print(f"\n--- Texte ---\n{text.strip()}\n")

    # Ingestion
    ingestion_service.process_input(
        input_data=text,
        employee=employee_id,
        tags=["tech", "ia"],
        origin="test_ner"
    )

    # V√©rification
    print("\nüîç V√©rification des m√©tadonn√©es du chunk...")
    results = chunk_repository.search("Microsoft", employee_id, limit=1)
    
    if results['metadatas'] and len(results['metadatas'][0]) > 0:
        meta = results['metadatas'][0][0]
        
        print("\nüìä M√©tadonn√©es trouv√©es :")
        print(json.dumps(meta, indent=2))
        
        # Tests
        has_people = "Satya Nadella" in meta.get("entities_people", "")
        has_company = "Microsoft" in meta.get("entities_companies", "")
        has_location = "Paris" in meta.get("entities_locations", "")

        if has_people and has_company:
            print("\n‚úÖ SUCC√àS : Entit√©s 'Satya Nadella' et 'Microsoft' d√©tect√©es !")
        else:
            print("\n‚ö†Ô∏è AVERTISSEMENT : Certaines entit√©s manquent.")
    else:
        print("‚ùå Erreur : Chunk introuvable.")

if __name__ == "__main__":
    run_entity_test()

# ------------------------------------------
# FICHIER : scripts\verify_hypothetical.py
# ------------------------------------------
import sys
import os
import logging

logging.basicConfig(level=logging.INFO)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database.connection import engine
from database.models import Base
from services.ingestion import ingestion_service
from repositories.chunk import chunk_repository

def run_test():
    print("üöÄ Test: Chunking avec Questions Hypoth√©tiques...")
    Base.metadata.create_all(bind=engine)
    
    # Texte court mais factuel, propice aux questions
    text = """
    La tour Eiffel est une tour de fer puddl√© de 330 m de hauteur situ√©e √† Paris.
    Construite par Gustave Eiffel pour l'Exposition universelle de Paris de 1889.
    Elle a accueilli plus de 300 millions de visiteurs depuis son ouverture.
    """
    
    doc_id = "test_eiffel_questions"
    employee_id = "tester_hyde"

    # Ingestion
    ingestion_service.process_input(
        input_data=text,
        employee=employee_id,
        tags=["monument", "paris"],
        origin="test_script"
    )

    # V√©rification
    print("\nüîç V√©rification du contenu du chunk...")
    # On r√©cup√®re le dernier chunk ins√©r√© pour ce doc
    results = chunk_repository.search("tour eiffel", employee_id, limit=1)
    
    if results['documents'] and results['documents'][0]:
        content = results['documents'][0][0]
        print("-" * 40)
        print(content)
        print("-" * 40)
        
        if "--- Questions Potentielles ---" in content:
            print("‚úÖ SUCC√àS : Les questions ont √©t√© g√©n√©r√©es et ajout√©es !")
        else:
            print("‚ùå √âCHEC : Pas de questions trouv√©es dans le texte.")
    else:
        print("‚ùå Erreur : Chunk introuvable.")

if __name__ == "__main__":
    run_test()
